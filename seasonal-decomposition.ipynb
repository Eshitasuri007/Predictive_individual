{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8084680,"sourceType":"datasetVersion","datasetId":4772301}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Time series analysis of flight delays**","metadata":{}},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"This project aims at performing a time series analysis to forecast the departure delays in the US from 2019 to 2023 and presents with an opportunity to analyse the challenges and enhance the operational efficiency and passenger satisfaction in the aviation industry. The project begins with a comprehensive examination of historical flight data, focusing on the `DEP_DELAY` variable that represents the length of delay at the time of departure. The data is preprocessed to handle irregularities, such as missing values and outliers, which are common in real-world datasets. And thereater a extensive EDA is performed to explore the data for underlying patterns and trends using visual and statistical methods. ","metadata":{}},{"cell_type":"markdown","source":"The ultimate goal is to deliver a robust predictive model that can be used by stakeholders to anticipate and manage departure delays, thereby minimizing their impact on flight schedules and passenger plans.","metadata":{}},{"cell_type":"code","source":"#importing all the necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:03:16.907749Z","iopub.execute_input":"2024-04-21T00:03:16.908478Z","iopub.status.idle":"2024-04-21T00:03:20.909533Z","shell.execute_reply.started":"2024-04-21T00:03:16.908442Z","shell.execute_reply":"2024-04-21T00:03:20.908307Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndata = pd.read_csv('/kaggle/input/flights-sample-3m/flights_sample_3m.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:04:19.639277Z","iopub.execute_input":"2024-04-21T00:04:19.639875Z","iopub.status.idle":"2024-04-21T00:04:35.677979Z","shell.execute_reply.started":"2024-04-21T00:04:19.639838Z","shell.execute_reply":"2024-04-21T00:04:35.676889Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of the dataframe\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:04:41.622898Z","iopub.execute_input":"2024-04-21T00:04:41.623510Z","iopub.status.idle":"2024-04-21T00:04:41.660896Z","shell.execute_reply.started":"2024-04-21T00:04:41.623481Z","shell.execute_reply":"2024-04-21T00:04:41.659558Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      FL_DATE                AIRLINE                AIRLINE_DOT AIRLINE_CODE  \\\n0  2019-01-09  United Air Lines Inc.  United Air Lines Inc.: UA           UA   \n1  2022-11-19   Delta Air Lines Inc.   Delta Air Lines Inc.: DL           DL   \n2  2022-07-22  United Air Lines Inc.  United Air Lines Inc.: UA           UA   \n3  2023-03-06   Delta Air Lines Inc.   Delta Air Lines Inc.: DL           DL   \n4  2020-02-23       Spirit Air Lines       Spirit Air Lines: NK           NK   \n\n   DOT_CODE  FL_NUMBER ORIGIN          ORIGIN_CITY DEST  \\\n0     19977       1562    FLL  Fort Lauderdale, FL  EWR   \n1     19790       1149    MSP      Minneapolis, MN  SEA   \n2     19977        459    DEN           Denver, CO  MSP   \n3     19790       2295    MSP      Minneapolis, MN  SFO   \n4     20416        407    MCO          Orlando, FL  DFW   \n\n               DEST_CITY  ...  DIVERTED  CRS_ELAPSED_TIME  ELAPSED_TIME  \\\n0             Newark, NJ  ...       0.0             186.0         176.0   \n1            Seattle, WA  ...       0.0             235.0         236.0   \n2        Minneapolis, MN  ...       0.0             118.0         112.0   \n3      San Francisco, CA  ...       0.0             260.0         285.0   \n4  Dallas/Fort Worth, TX  ...       0.0             181.0         182.0   \n\n   AIR_TIME  DISTANCE  DELAY_DUE_CARRIER  DELAY_DUE_WEATHER  DELAY_DUE_NAS  \\\n0     153.0    1065.0                NaN                NaN            NaN   \n1     189.0    1399.0                NaN                NaN            NaN   \n2      87.0     680.0                NaN                NaN            NaN   \n3     249.0    1589.0                0.0                0.0           24.0   \n4     153.0     985.0                NaN                NaN            NaN   \n\n   DELAY_DUE_SECURITY  DELAY_DUE_LATE_AIRCRAFT  \n0                 NaN                      NaN  \n1                 NaN                      NaN  \n2                 NaN                      NaN  \n3                 0.0                      0.0  \n4                 NaN                      NaN  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FL_DATE</th>\n      <th>AIRLINE</th>\n      <th>AIRLINE_DOT</th>\n      <th>AIRLINE_CODE</th>\n      <th>DOT_CODE</th>\n      <th>FL_NUMBER</th>\n      <th>ORIGIN</th>\n      <th>ORIGIN_CITY</th>\n      <th>DEST</th>\n      <th>DEST_CITY</th>\n      <th>...</th>\n      <th>DIVERTED</th>\n      <th>CRS_ELAPSED_TIME</th>\n      <th>ELAPSED_TIME</th>\n      <th>AIR_TIME</th>\n      <th>DISTANCE</th>\n      <th>DELAY_DUE_CARRIER</th>\n      <th>DELAY_DUE_WEATHER</th>\n      <th>DELAY_DUE_NAS</th>\n      <th>DELAY_DUE_SECURITY</th>\n      <th>DELAY_DUE_LATE_AIRCRAFT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-09</td>\n      <td>United Air Lines Inc.</td>\n      <td>United Air Lines Inc.: UA</td>\n      <td>UA</td>\n      <td>19977</td>\n      <td>1562</td>\n      <td>FLL</td>\n      <td>Fort Lauderdale, FL</td>\n      <td>EWR</td>\n      <td>Newark, NJ</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>186.0</td>\n      <td>176.0</td>\n      <td>153.0</td>\n      <td>1065.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-11-19</td>\n      <td>Delta Air Lines Inc.</td>\n      <td>Delta Air Lines Inc.: DL</td>\n      <td>DL</td>\n      <td>19790</td>\n      <td>1149</td>\n      <td>MSP</td>\n      <td>Minneapolis, MN</td>\n      <td>SEA</td>\n      <td>Seattle, WA</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>235.0</td>\n      <td>236.0</td>\n      <td>189.0</td>\n      <td>1399.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-07-22</td>\n      <td>United Air Lines Inc.</td>\n      <td>United Air Lines Inc.: UA</td>\n      <td>UA</td>\n      <td>19977</td>\n      <td>459</td>\n      <td>DEN</td>\n      <td>Denver, CO</td>\n      <td>MSP</td>\n      <td>Minneapolis, MN</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>118.0</td>\n      <td>112.0</td>\n      <td>87.0</td>\n      <td>680.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-03-06</td>\n      <td>Delta Air Lines Inc.</td>\n      <td>Delta Air Lines Inc.: DL</td>\n      <td>DL</td>\n      <td>19790</td>\n      <td>2295</td>\n      <td>MSP</td>\n      <td>Minneapolis, MN</td>\n      <td>SFO</td>\n      <td>San Francisco, CA</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>260.0</td>\n      <td>285.0</td>\n      <td>249.0</td>\n      <td>1589.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-02-23</td>\n      <td>Spirit Air Lines</td>\n      <td>Spirit Air Lines: NK</td>\n      <td>NK</td>\n      <td>20416</td>\n      <td>407</td>\n      <td>MCO</td>\n      <td>Orlando, FL</td>\n      <td>DFW</td>\n      <td>Dallas/Fort Worth, TX</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>181.0</td>\n      <td>182.0</td>\n      <td>153.0</td>\n      <td>985.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:04:48.406211Z","iopub.execute_input":"2024-04-21T00:04:48.406885Z","iopub.status.idle":"2024-04-21T00:04:48.413990Z","shell.execute_reply.started":"2024-04-21T00:04:48.406851Z","shell.execute_reply":"2024-04-21T00:04:48.412904Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['FL_DATE', 'AIRLINE', 'AIRLINE_DOT', 'AIRLINE_CODE', 'DOT_CODE',\n       'FL_NUMBER', 'ORIGIN', 'ORIGIN_CITY', 'DEST', 'DEST_CITY',\n       'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF',\n       'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n       'CANCELLED', 'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME',\n       'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'DELAY_DUE_CARRIER',\n       'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS', 'DELAY_DUE_SECURITY',\n       'DELAY_DUE_LATE_AIRCRAFT'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"# Convert dates to datetime and extract relevant parts\ndata['FL_DATE'] = pd.to_datetime(data['FL_DATE'])\ndata['YEAR'] = data['FL_DATE'].dt.year\ndata['MONTH'] = data['FL_DATE'].dt.month\ndata['DAY'] = data['FL_DATE'].dt.day\ndata['WEEKDAY'] = data['FL_DATE'].dt.weekday\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:05:27.303988Z","iopub.execute_input":"2024-04-21T00:05:27.304740Z","iopub.status.idle":"2024-04-21T00:05:28.819695Z","shell.execute_reply.started":"2024-04-21T00:05:27.304697Z","shell.execute_reply":"2024-04-21T00:05:28.818738Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data['FL_NUMBER'] = data['FL_NUMBER'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:05:42.227576Z","iopub.execute_input":"2024-04-21T00:05:42.228006Z","iopub.status.idle":"2024-04-21T00:05:43.877211Z","shell.execute_reply.started":"2024-04-21T00:05:42.227973Z","shell.execute_reply":"2024-04-21T00:05:43.875914Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Remove duplicates\ndata.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:06:39.914465Z","iopub.execute_input":"2024-04-21T00:06:39.914878Z","iopub.status.idle":"2024-04-21T00:06:46.712101Z","shell.execute_reply.started":"2024-04-21T00:06:39.914849Z","shell.execute_reply":"2024-04-21T00:06:46.711060Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Check missing value of each column\nmissing_percentage = (data.isnull().sum() / len(data)) * 100\nprint(missing_percentage)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:06:46.714024Z","iopub.execute_input":"2024-04-21T00:06:46.714493Z","iopub.status.idle":"2024-04-21T00:06:49.509838Z","shell.execute_reply.started":"2024-04-21T00:06:46.714454Z","shell.execute_reply":"2024-04-21T00:06:49.508610Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"FL_DATE                     0.000000\nAIRLINE                     0.000000\nAIRLINE_DOT                 0.000000\nAIRLINE_CODE                0.000000\nDOT_CODE                    0.000000\nFL_NUMBER                   0.000000\nORIGIN                      0.000000\nORIGIN_CITY                 0.000000\nDEST                        0.000000\nDEST_CITY                   0.000000\nCRS_DEP_TIME                0.000000\nDEP_TIME                    2.587167\nDEP_DELAY                   2.588133\nTAXI_OUT                    2.626867\nWHEELS_OFF                  2.626867\nWHEELS_ON                   2.664800\nTAXI_IN                     2.664800\nCRS_ARR_TIME                0.000000\nARR_TIME                    2.664733\nARR_DELAY                   2.873267\nCANCELLED                   0.000000\nCANCELLATION_CODE          97.362000\nDIVERTED                    0.000000\nCRS_ELAPSED_TIME            0.000467\nELAPSED_TIME                2.873267\nAIR_TIME                    2.873267\nDISTANCE                    0.000000\nDELAY_DUE_CARRIER          82.204567\nDELAY_DUE_WEATHER          82.204567\nDELAY_DUE_NAS              82.204567\nDELAY_DUE_SECURITY         82.204567\nDELAY_DUE_LATE_AIRCRAFT    82.204567\nYEAR                        0.000000\nMONTH                       0.000000\nDAY                         0.000000\nWEEKDAY                     0.000000\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fill missing values for features with low missing percentages with the median\nfor col in ['DEP_TIME', 'DEP_DELAY', 'ARR_DELAY', 'TAXI_OUT', 'WHEELS_OFF', \n            'WHEELS_ON', 'TAXI_IN', 'ARR_TIME', 'ELAPSED_TIME', 'AIR_TIME']:\n    data[col].fillna(data[col].median(), inplace=True)\n\n# Fill missing values for delay reasons with zero\nfor col in ['DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS', \n            'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT']:\n    data[col].fillna(0, inplace=True)\n\n# Fill missing values for CANCELLATION_CODE with 'Not Canceled'\ndata['CANCELLATION_CODE'].fillna('Not Canceled', inplace=True)\n\n# Check if any more missing values need to be addressed\nprint(data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:07:14.044797Z","iopub.execute_input":"2024-04-21T00:07:14.045203Z","iopub.status.idle":"2024-04-21T00:07:17.952064Z","shell.execute_reply.started":"2024-04-21T00:07:14.045175Z","shell.execute_reply":"2024-04-21T00:07:17.950931Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(data[col].median(), inplace=True)\n/tmp/ipykernel_55/1353765903.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[col].fillna(0, inplace=True)\n/tmp/ipykernel_55/1353765903.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['CANCELLATION_CODE'].fillna('Not Canceled', inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"FL_DATE                     0\nAIRLINE                     0\nAIRLINE_DOT                 0\nAIRLINE_CODE                0\nDOT_CODE                    0\nFL_NUMBER                   0\nORIGIN                      0\nORIGIN_CITY                 0\nDEST                        0\nDEST_CITY                   0\nCRS_DEP_TIME                0\nDEP_TIME                    0\nDEP_DELAY                   0\nTAXI_OUT                    0\nWHEELS_OFF                  0\nWHEELS_ON                   0\nTAXI_IN                     0\nCRS_ARR_TIME                0\nARR_TIME                    0\nARR_DELAY                   0\nCANCELLED                   0\nCANCELLATION_CODE           0\nDIVERTED                    0\nCRS_ELAPSED_TIME           14\nELAPSED_TIME                0\nAIR_TIME                    0\nDISTANCE                    0\nDELAY_DUE_CARRIER           0\nDELAY_DUE_WEATHER           0\nDELAY_DUE_NAS               0\nDELAY_DUE_SECURITY          0\nDELAY_DUE_LATE_AIRCRAFT     0\nYEAR                        0\nMONTH                       0\nDAY                         0\nWEEKDAY                     0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_full = df_full = data[['FL_DATE', 'DEP_DELAY', 'ARR_DELAY']].copy()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:12:04.493839Z","iopub.execute_input":"2024-04-21T00:12:04.494307Z","iopub.status.idle":"2024-04-21T00:12:04.539829Z","shell.execute_reply.started":"2024-04-21T00:12:04.494274Z","shell.execute_reply":"2024-04-21T00:12:04.538257Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Preparing the dataset for EDA\n#df_full = pd.read_csv('/kaggle/input/flights-sample-3m/flights_sample_3m.csv', usecols=['FL_DATE', 'DEP_DELAY', 'ARR_DELAY'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:03:25.989441Z","iopub.execute_input":"2024-04-21T00:03:25.989999Z","iopub.status.idle":"2024-04-21T00:03:39.851787Z","shell.execute_reply.started":"2024-04-21T00:03:25.989964Z","shell.execute_reply":"2024-04-21T00:03:39.850587Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_full.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:12:15.307898Z","iopub.execute_input":"2024-04-21T00:12:15.308305Z","iopub.status.idle":"2024-04-21T00:12:15.321291Z","shell.execute_reply.started":"2024-04-21T00:12:15.308274Z","shell.execute_reply":"2024-04-21T00:12:15.320043Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"     FL_DATE  DEP_DELAY  ARR_DELAY\n0 2019-01-09       -4.0      -14.0\n1 2022-11-19       -6.0       -5.0\n2 2022-07-22        6.0        0.0\n3 2023-03-06       -1.0       24.0\n4 2020-02-23       -2.0       -1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FL_DATE</th>\n      <th>DEP_DELAY</th>\n      <th>ARR_DELAY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-09</td>\n      <td>-4.0</td>\n      <td>-14.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-11-19</td>\n      <td>-6.0</td>\n      <td>-5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-07-22</td>\n      <td>6.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-03-06</td>\n      <td>-1.0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-02-23</td>\n      <td>-2.0</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Converting FL_DATE to datetime and setting it as the index\ndf_full['FL_DATE'] = pd.to_datetime(df_full['FL_DATE'])\ndf_full.set_index('FL_DATE', inplace=True)\n\n# Aggregating data to daily average delays\ndaily_avg_delays = df_full.resample('D').mean()\n\n# Displaying the first few rows to verify the transformation\ndaily_avg_delays.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA - Seaonal Decomposition ","metadata":{}},{"cell_type":"code","source":"# Setting the visual style\nsns.set(style=\"whitegrid\")\n\n# Plotting the daily average departure and arrival delays\nplt.figure(figsize=(15, 7))\nplt.plot(daily_avg_delays.index, daily_avg_delays['DEP_DELAY'], label='Average Departure Delay', color='blue')\nplt.plot(daily_avg_delays.index, daily_avg_delays['ARR_DELAY'], label='Average Arrival Delay', color='red')\nplt.title('Daily Average Flight Delays (2019-2023)')\nplt.xlabel('Date')\nplt.ylabel('Average Delay (minutes)')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resampling the time series data to a daily frequency ('D'), grouping the data by each day and then calculating the mean of each group. 'daily_avg_delays': daily average values of flight delays","metadata":{}},{"cell_type":"code","source":"# Decomposing the daily average departure delays\ndecomposition = seasonal_decompose(daily_avg_delays['DEP_DELAY'], model='additive')\n\n# Plotting the decomposed time series components\nfig = decomposition.plot()\nfig.set_size_inches(14, 7)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"X-axis: data in range 2019 to sometime in 2023. \nY-axis: the magnitude of the departure delays, trend, seasonal effect, and residuals.\nFirst graph shows the orignial time series data with the daily average departure delays, next one shows the trend of long term progression of the original time series. Third graph shows the seasonality component which in this case is on daily basis and shows a consyant pattern indicadting that as it is plotted against several years of data, daily fluctuations can blend together and look like a solid, unchanging band.The last graph is the spread of the residuals and it seems to be consistent over time, suggesting homoscedasticity, which means the variance of the residuals is fairly uniform. There are a few points that stand out from the zero line, which could be considered as outliers.","metadata":{}},{"cell_type":"code","source":"\nflights_data = pd.read_csv('/kaggle/input/flights-sample-3m/flights_sample_3m.csv', parse_dates=['FL_DATE'])\n\n# Set date as index \nflights_data.set_index('FL_DATE', inplace=True)\n\n# Creating new features\n# Time of Day\nflights_data['hour_of_day'] = flights_data['CRS_DEP_TIME'].apply(lambda x: int(str(x).zfill(4)[:2]))\n\n# Day of the Week\nflights_data['day_of_week'] = flights_data.index.dayofweek\n\n# Month and Season\nflights_data['month'] = flights_data.index.month\nflights_data['season'] = flights_data['month'] % 12 // 3 + 1\n\n# Weekend Indicator\nflights_data['is_weekend'] = flights_data['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n\n# Create categories for distance\nflights_data['distance_category'] = pd.cut(flights_data['DISTANCE'], bins=[0, 500, 1000, 1500, 2000, float('inf')], \n                                           labels=['Very Short', 'Short', 'Medium', 'Long', 'Very Long'])\n\nprint(flights_data.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the visualisation style\nsns.set(style=\"whitegrid\")\n \n# EDA: Departure Delays by Hour of Day\nplt.figure(figsize=(14, 7))\nsns.boxplot(x='hour_of_day', y='DEP_DELAY', data=flights_data)\nplt.title('Departure Delays by Hour of Day')\nplt.xlabel('Hour of Day')\nplt.ylabel('Departure Delay (minutes)')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The median delay across most hours seems to be quite low and there is a significant variation in delays, as shown by the range of the boxes and the whiskers for each hour. There are many outliers, especially in the daytime and evening hours, indicating that while most delays are moderate, there are quite a few instances of extreme delays. Certain hours in the evening show a higher median delay, indicating that more than half of the delays recorded during these times are on the higher side compared to other hours.","metadata":{}},{"cell_type":"code","source":"# Function to calculate mean and standard error for plotting with error bars\ndef mean_sem(group):\n    return {'mean': group.mean(), 'sem': group.sem()}\n\n# Mean and standard error of departure delays by hour of day\nhourly_delay = flights_data.groupby('hour_of_day')['DEP_DELAY'].apply(mean_sem).unstack()\n\n# Plotting mean departure delay by hour of day with error bars\nplt.figure(figsize=(14, 7))\nplt.errorbar(x=hourly_delay.index, y=hourly_delay['mean'], yerr=hourly_delay['sem'], fmt='o')\nplt.title('Mean Departure Delay by Hour of Day with Error Bars')\nplt.xlabel('Hour of Day')\nplt.ylabel('Mean Departure Delay (minutes)')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The points indicate the average departure delay for flights at different hours of the day. The error bars show the variability around the mean, which can be interpreted as the range within which we expect the true mean delay to fall. They appear to represent one standard error above and below the mean. There's a clear pattern where the mean delay increases during certain hours of the day, peaking in the late afternoon and evening. This suggests that flights are more likely to be delayed during these hours. The variability also seems to increase during the day, with wider error bars observed in the afternoon and evening, indicating less consistency in flight delays during these times.","metadata":{}},{"cell_type":"code","source":"# EDA: Departure Delays by Day of Week\nplt.figure(figsize=(14, 7))\nsns.boxplot(x='day_of_week', y='DEP_DELAY', data=flights_data)\nplt.title('Departure Delays by Day of the Week')\nplt.xlabel('Day of the Week')\nplt.ylabel('Departure Delay (minutes)')\n# Setting the x-axis labels to be more descriptive\nplt.xticks(ticks=[0, 1, 2, 3, 4, 5, 6], labels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bar plot for mean departure delay by day of the week\nplt.figure(figsize=(14, 7))\nweekday_mean_delays = flights_data.groupby('day_of_week')['DEP_DELAY'].mean()\nsns.barplot(x=weekday_mean_delays.index, y=weekday_mean_delays.values)\nplt.title('Average Departure Delay by Day of the Week')\nplt.xlabel('Day of the Week')\nplt.ylabel('Average Departure Delay (minutes)')\nplt.xticks(ticks=[0, 1, 2, 3, 4, 5, 6], labels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a consistent pattern of delays throughout the week and no single day stands out as having markedly longer delays.\nThe mean departure is slightly lower of tuesdays and Wednesdays. ","metadata":{}},{"cell_type":"code","source":"# EDA: Departure Delays by Season\nplt.figure(figsize=(14, 7))\nsns.boxplot(x='season', y='DEP_DELAY', data=flights_data)\nplt.title('Departure Delays by Season')\nplt.xlabel('Season')\nplt.ylabel('Departure Delay (minutes)')\n# Setting the x-axis labels to be more descriptive\nplt.xticks(ticks=[0, 1, 2, 3], labels=['Winter', 'Spring', 'Summer', 'Autumn'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bar plot for mean departure delay by season\nplt.figure(figsize=(14, 7))\nseason_mean_delays = flights_data.groupby('season')['DEP_DELAY'].mean()\nsns.barplot(x=season_mean_delays.index, y=season_mean_delays.values)\nplt.title('Average Departure Delay by Season')\nplt.xlabel('Season')\nplt.ylabel('Average Departure Delay (minutes)')\nplt.xticks(ticks=[0, 1, 2, 3], labels=['Winter', 'Spring', 'Summer', 'Autumn'])\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Winter has the highest average delay, which could be attributed to winter weather conditions affecting flight operations. Summer also shows a high average delay, which might be due to increased travel activity. \nSpring and autumn show lower average delays, which might be due to more favorable weather conditions and possibly fewer flights compared to the high travel seasons.","metadata":{}},{"cell_type":"code","source":"# EDA: Departure Delays by Distance Category\nplt.figure(figsize=(14, 7))\nsns.boxplot(x='distance_category', y='DEP_DELAY', data=flights_data)\nplt.title('Departure Delays by Distance Category')\nplt.xlabel('Distance Category')\nplt.ylabel('Departure Delay (minutes)')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ‘Very Short’ and ‘Very Long’ distance categories have a higher median delay as compared to the other three categories. Additionally, the very long flights also experiencing some of the most extreme delays. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 7))\nflights_data['DEP_DELAY'].resample('MS').mean().plot()\nplt.title('Monthly Average Departure Delay Over Time')\nplt.xlabel('Month')\nplt.ylabel('Average Departure Delay (minutes)')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is some seasonality in the data, with peaks and troughs corresponding to specific times of the year. Starting from around the beginning of 2021, there's a noticeable upward trend in the average departure delay. This trend continues into 2022 and 2023, suggesting that, on average, delays have been getting longer over these years.","metadata":{}},{"cell_type":"code","source":"# KDE plot of departure delays\nplt.figure(figsize=(14, 7))\nsns.histplot(flights_data['DEP_DELAY'].dropna(), bins=50, kde=True)  # Drop NaN values for this plot\nplt.title('Distribution of Departure Delays')\nplt.xlabel('Departure Delay (minutes)')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution is right-skewed, indicating that there are more instances of shorter delays and much fewer instances of longer delays. The long tail extending to the right shows that there are relatively few flights with large delays.","metadata":{}},{"cell_type":"code","source":"# Grouping the data by 'AIRLINE' and calculate mean and standard deviation of 'DEP_DELAY'\nairline_delays = flights_data.groupby('AIRLINE')['DEP_DELAY'].agg(['mean', 'std']).reset_index()\n\n# Sorting the results for better visualization\nairline_delays = airline_delays.sort_values(by='mean')\n\n# Bar plot of average delays by airline\nplt.figure(figsize=(14, 7))\nsns.barplot(x='mean', y='AIRLINE', data=airline_delays, ci='sd')  # 'ci' for confidence interval, which here means standard deviation\nplt.xlabel('Average Delay (minutes)')\nplt.ylabel('Airline')\nplt.title('Average Departure Delay by Airline')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The specific positioning describes how long is the delay and how predictable are they. Airlines at the top of the chart such as Alaska and Horizon are generally more reliable in terms of having lower and more consistent departure delays, while those at the bottom like Frontier and JetBlue have longer and more unpredictable delay patterns.","metadata":{}},{"cell_type":"code","source":"# Grouping the data by 'hour_of_day' and 'AIRLINE', then calculate the mean delay\nhourly_airline_delay = flights_data.groupby(['hour_of_day', 'AIRLINE'])['DEP_DELAY'].mean().reset_index()\n\n# Creating a point plot to show the interaction between airline and hour of day for delays\nplt.figure(figsize=(18, 10))\nsns.pointplot(x='hour_of_day', y='DEP_DELAY', hue='AIRLINE', data=hourly_airline_delay)\nplt.title('Average Departure Delay by Airline Across Different Hours of the Day')\nplt.xlabel('Hour of Day')\nplt.ylabel('Average Departure Delay (minutes)')\nplt.legend(title='Airline', bbox_to_anchor=(1.05, 1), loc='upper left')  # Move the legend out of the plot\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most airlines seem to have a relatively low and consistent average departure delay across all the hours.","metadata":{}},{"cell_type":"code","source":" # Step 1: Identifying the airlines with the most flights\ntop_airlines = flights_data['AIRLINE'].value_counts().nlargest(5).index\n\n# Step 2: Filtering the dataset to include only the top airlines\ntop_airlines_data = flights_data[flights_data['AIRLINE'].isin(top_airlines)]\n\n# Step 3: Calculating the mean delay for these airlines by hour\ntop_hourly_delay = top_airlines_data.groupby(['hour_of_day', 'AIRLINE'])['DEP_DELAY'].mean().reset_index()\n\n# Step 4: Creating v. vvb                                                      b.    gvv  the visualization\nplt.figure(figsize=(18, 10))\nsns.pointplot(x='hour_of_day', y='DEP_DELAY', hue='AIRLINE', data=top_hourly_delay, \n              palette='tab10', ci=None)  # ci=None will not show the confidence interval\nplt.title('Average Departure Delay by Top Airlines Across Different Hours of the Day')\nplt.xlabel('Hour of Day')\nplt.ylabel('Average Departure Delay (minutes)')\nplt.legend(title='Airline', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is variability in the average delays across different hours for the airlines. Specific hours of concern include early morning 5 am, Midday to early afternoon from 10 am to 2 pm and evening around 8 pm and 9 pm where there is a general increase in delays for most airlines, possibly due to the cumulative effect of delays throughout the day or reduced operational efficiency during late hours.","metadata":{}},{"cell_type":"code","source":"flights_data.sort_index(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flights_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('FL_DATE' in flights_data.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flights_data = flights_data[~flights_data.index.duplicated(keep='first')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating a subset data to split it into testing and training. The first three years of data will be used for training and the next two for testing the predicted values.","metadata":{}},{"cell_type":"code","source":"#subset_data = flights_data['2022-01-01':'2023-12-31'] #test data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the split date\nsplit_date = pd.Timestamp('2021-12-31')\n\n# Splitting the data into training and test sets\ntrain_data = flights_data.loc[flights_data.index <= split_date]\ntest_data = flights_data.loc[flights_data.index > split_date]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmented Dickey-Fuller (ADF) test ","metadata":{}},{"cell_type":"code","source":"# Performing the ADF test on the train subset for stationarity\nadf_result_subset = adfuller(train_data['DEP_DELAY'].dropna())\n\nprint('ADF Statistic: %f' % adf_result_subset[0])\nprint('p-value: %f' % adf_result_subset[1])\nprint('Critical Values:')\nfor key, value in adf_result_subset[4].items():\n    print('\\t%s: %.3f' % (key, value))\n\n# Interpret the results\nif adf_result_subset[1] > 0.05:\n    print(\"The time series subset is likely non-stationary.\")\nelse:\n    print(\"The time series subset is likely stationary.\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performing ADF on training data to check the stationarity of data. The negative value suggest that the null hypothesis is false, and the data is stationary. Additionally, p-value below the threshold indicates towards rejecting the null hypothesis in favour of the alternative hypothesis that the series is stationary. The ADF statistic here is lower than all the critical value thresholds (1%, 5%, and 10%), further supporting the conclusion that the time series is stationary.\n\nThis result confirms that I can apply time series forecasting models that assume stationarity (like ARIMA) on the 'DEP_DELAY' data with some confidence that they are appropriate for this dataset. \n","metadata":{}},{"cell_type":"code","source":"# ACF and PACF plots\nfig, axes = plt.subplots(2, 1, figsize=(12, 12))\n\n# Plot the Autocorrelation Function (ACF)\nplot_acf(train_data['DEP_DELAY'].dropna(), lags=50, ax=axes[0])\n \n# Plot the Partial Autocorrelation Function (PACF)\nplot_pacf(train_data['DEP_DELAY'].dropna(), lags=50, ax=axes[1])\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performing ACF and PACF plots to identify the proper terms and lags to include in time series models for relevant forecasting.\n\nThere is a strong autocorrelation at lag 1 for both ACF and PACF which shows that the departure delay ('DEP_DELAY') of a given time is significantly influenced by the departure delay in the immediately preceding time period.\n","metadata":{}},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"Starting with ARIMA(1, 0, 0) model which corresponds to a simple AR(1) model without the MA component, as there was no significant indication for MA terms from the ACF plot.","metadata":{}},{"cell_type":"markdown","source":"# ARIMA (1, 0, 0)","metadata":{}},{"cell_type":"code","source":"# Fitting the ARIMA(1, 0, 0) model\narima_model = ARIMA(train_data['DEP_DELAY'], order=(1, 0, 0))\narima_result = arima_model.fit()\n\n# Printing out the summary of the model fit\narima_result_summary = arima_result.summary()\nprint(arima_result_summary)\n\n# Plotting diagnostics to investigate any unusual behavior\narima_result.plot_diagnostics(figsize=(15, 12))\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model is not a good fit as the coefficient for the AR term is not significant and points towards including additional lags. The non-normality of residuals and substantial deviations in the Q-Q plot suggest that there might be non-linearity or other dynamics in the data. And there is a significant autocorrelation at lag 1 in the correlogram of the residuals which suggests that the model is inefficient in explain the temporal dependencies in the data.  ","metadata":{}},{"cell_type":"markdown","source":"# ARIMA(1, 0, 1)","metadata":{}},{"cell_type":"code","source":"# Fitting the model\narima_model = ARIMA(train_data['DEP_DELAY'], order=(1, 0, 1))\narima_result = arima_model.fit()\n\n# Printing out the summary\narima_result_summary = arima_result.summary()\nprint(arima_result_summary)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the diagnostics\narima_result.plot_diagnostics(figsize=(15, 12))\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the number of steps to forecast\nsteps_to_forecast = len(test_data)\n\n# Generating forecasts\nforecast_results = arima_result.get_forecast(steps=steps_to_forecast)\n\n\nforecast_mean = forecast_results.predicted_mean\nforecast_conf_int = forecast_results.conf_int()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the actual values\nplt.figure(figsize=(10, 6))\nplt.plot(train_data.index, train_data['DEP_DELAY'], label='Train Actuals')\nplt.plot(test_data.index, test_data['DEP_DELAY'], label='Test Actuals')\n\n# Plot the predicted values (forecast_mean)\nplt.plot(forecast_mean.index, forecast_mean, label='Forecast Mean')\n\n# Plot the confidence intervals (from forecast_conf_int)\nplt.fill_between(forecast_conf_int.index,\n                 forecast_conf_int['lower DEP_DELAY'],\n                 forecast_conf_int['upper DEP_DELAY'],\n                 color='pink', alpha=0.3, label='Confidence Interval')\n\nplt.title('Forecast vs Actuals')\nplt.xlabel('Date')\nplt.ylabel('Departure Delay (minutes)')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ARIMA(1, 0, 1) model captures some of the autocorrelation structure of the data which can be concluded by the significant coefficients like 'ar.L1' coefficient is approximately -0.9889 with a p-value of 0.000, which is highly significant and 'ma.L1' coefficient is approximately 0.9765 with a p-value of 0.000, indicating a highly significant moving average component that positively affects the current value. However, the non-normality of the residuals and the spikes in the standardized residuals plot suggest that there may be additional complexity in the data not captured by the model.","metadata":{}},{"cell_type":"markdown","source":"# ARIMA (2, 0, 0)","metadata":{}},{"cell_type":"code","source":"arima_model_202 = ARIMA(train_data['DEP_DELAY'], order=(2, 0, 2))\narima_result_202 = arima_model_202.fit()\n\n# summary of the model fit\nprint(arima_result_202.summary())\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are several issues in the model such as non-significant predictors and potential non-stationarity. Thereafter the diagnostic tests indicate good signs in terms of autocorrelation and heteroskedasticity but showcases that there is a problem with the normal distribution of residuals, concluding that the model is not the best fit. ","metadata":{}},{"cell_type":"code","source":"# Forecasting using the fitted model\nforecast = arima_result_202.get_forecast(steps=len(test_data))\n\n# The forecast object contains the predicted values, the standard error of predictions, and the confidence intervals\nforecast_values = forecast.predicted_mean\nforecast_conf_int = forecast.conf_int()\nforecast_se = forecast.se_mean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_nonan = test_data.dropna()\nforecast_values_nonan = forecast_values.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensuring both forecast_values and test_data['DEP_DELAY'] are pandas Series\nforecast_values = pd.Series(forecast_values)\ntest_data['DEP_DELAY'] = pd.Series(test_data['DEP_DELAY'])\n\n# Aligning forecast_values and test_data on their common index\ncommon_index = forecast_values.index.intersection(test_data['DEP_DELAY'].index)\nforecast_values_aligned = forecast_values.loc[common_index]\ntest_data_aligned = test_data['DEP_DELAY'].loc[common_index]\n\n# Plotting the actual vs forecasted values\nplt.figure(figsize=(10, 6))\nplt.plot(test_data_aligned.index, test_data_aligned, label='Actual', color='blue')\nplt.plot(forecast_values_aligned.index, forecast_values_aligned, label='Forecasted', color='red')\nplt.title('Actual vs Forecasted DEP_DELAY')\nplt.xlabel('Date')\nplt.ylabel('DEP_DELAY')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The forecasted values appear to be relatively flat, which suggests the model might be underfitting the data and not responsive enough to changes over time.\n","metadata":{}},{"cell_type":"markdown","source":"I tried to incorporate the SARIMA model but it is extremely computationally demanding as it tries to include both non-seasonal and seasonal elements, each with its own autoregressive (AR) parameters, differencing (I), and moving average (MA) parameter. Hence choosing a simpler model ETS which is more straightforward and faster to compute than SARIMA models and are particularly useful when you need a model that can be quickly retrained and updated as new data becomes available.","metadata":{}},{"cell_type":"markdown","source":"#  Error, Trend, and Seasonality (ETS) model","metadata":{}},{"cell_type":"code","source":"flights_data.index = pd.to_datetime(flights_data.index)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flights_data = flights_data.asfreq('D')  # for daily frequency","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making sure that the data does not contain zero or negative values before log transformation\ntrain_data['DEP_DELAY'] = train_data['DEP_DELAY'] + 1  \ntrain_data['Transformed_DEP_DELAY'] = np.log(train_data['DEP_DELAY'])\n\n# Replacing them \ntrain_data['Transformed_DEP_DELAY'] = train_data['Transformed_DEP_DELAY'].replace([np.inf, -np.inf], np.nan)\ntrain_data.dropna(subset=['Transformed_DEP_DELAY'], inplace=True)\n\n# Fitting the ETS model with log-transformed data\nets_model = ExponentialSmoothing(\n    train_data['Transformed_DEP_DELAY'],\n    trend='add',\n    seasonal='add',\n    seasonal_periods=7,  # or another appropriate value based on your domain knowledge\n    initialization_method='estimated'\n)\nets_result = ets_model.fit()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forecasting using the fitted model\nsteps_to_forecast = len(test_data)  \npredictions = ets_result.forecast(steps=steps_to_forecast)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inversing the transformation for the predictions before comparing with the actual values\npredictions = np.exp(predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting the residuals\nresiduals = ets_result.resid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the residuals\nplt.figure(figsize=(12, 6))\nplt.plot(residuals, label='Residuals', color='blue')\nplt.axhline(0, linestyle='--', color='black')  # Add a horizontal line at 0\nplt.title('Residuals from ETS Model')\nplt.xlabel('Date')\nplt.ylabel('Residuals')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph is shows the error of the model's predictions for flight departure delays over time. Since the residuals are not close to zero and there are spikes corresponding to specific days where delays were particularly unpredictable, we can conclude that the model consistently failed to predict the actual delay and needs to be improved.","metadata":{}},{"cell_type":"code","source":"# Additional diagnostic plots\n# Histogram of the residuals\nplt.figure(figsize=(12, 6))\nplt.hist(residuals, bins=25, color='blue', edgecolor='black')\nplt.title('Histogram of Residuals')\nplt.xlabel('Residuals')\nplt.ylabel('Frequency')\nplt.show()\n\n# ACF plot of the residuals\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(residuals, lags=40)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MAE and MSE for the training set\nmae = np.mean(np.abs(residuals))\nmse = np.mean(residuals**2)\nprint(f\"MAE: {mae}, MSE: {mse}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the actual vs forecasted values\nplt.figure(figsize=(10, 4))\nplt.plot(test_data.index, test_data['DEP_DELAY'], label='Actual')\nplt.plot(test_data.index[-steps_to_forecast:], predictions, label='Forecasted', linestyle='--')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is underperforming and needs some parameters tunning. I was not sure about the spikes on the graph and therefore decided to proceed with anamoly detection and handle those and try the ETS model again. ","metadata":{}},{"cell_type":"markdown","source":"# Anomaly detection on the DEP_DELAY column","metadata":{}},{"cell_type":"code","source":"# Ensuring that there is no missing values in the 'DEP_DELAY' column\nflights_data = flights_data.dropna(subset=['DEP_DELAY'])\n\n# Initializing the IsolationForest model\niforest = IsolationForest(n_estimators=100, contamination=0.01)  # Adjust contamination if you have an expected outlier ratio\n\n# Reshaping the data using .values.reshape(-1, 1) since there is a single feature\niforest.fit(flights_data[['DEP_DELAY']].values.reshape(-1, 1))\n\n# Predicting the anomalies (-1 for outliers, 1 for inliers)\nflights_data['anomaly'] = iforest.predict(flights_data[['DEP_DELAY']].values.reshape(-1, 1))\n\n# Filtering out the anomalies to get a DataFrame without outliers\nflights_data_no_anomaly = flights_data[flights_data['anomaly'] == 1]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_date = pd.Timestamp('2021-12-31')\n\n# Splitting the data into training and test sets\ntrain_data_new = flights_data_no_anomaly.loc[flights_data_no_anomaly.index <= split_date]\ntest_data_new = flights_data_no_anomaly.loc[flights_data_no_anomaly.index > split_date]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_series = train_data_new['DEP_DELAY']\n\n# Fitting the ETS model on the training series\nets_model = ExponentialSmoothing(train_series, trend='add', seasonal='add', seasonal_periods=365)\nets_fit = ets_model.fit()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forecastting the future values using the fitted model\nforecast_length = len(test_data_new)\nforecast_values = ets_fit.forecast(steps=forecast_length)\n\n# Adding the forecasted values to the test_data DataFrame for comparison\ntest_data_new['Forecast'] = forecast_values.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_data_new['Forecast'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecasted_values_list = test_data_new['Forecast'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_of_items = len(forecasted_values_list)\nprint(count_of_items) # as the test_data is for about 2 years or 20 months. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_new.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_new.to_csv('test_data_new.csv', index=False) # created this for the group project","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_new['FL_DATE'] = test_data_new.index\n\nplt.figure(figsize=(15, 7))\nplt.plot(test_data_new['FL_DATE'], test_data_new['DEP_DELAY'], label='Actual', color='blue')\nplt.plot(test_data_new['FL_DATE'], test_data_new['Forecast'], label='Forecasted', color='orange', linestyle='--')\n\nplt.title('Actual vs Forecasted Departure Delays')\nplt.xlabel('Date')\nplt.ylabel('Departure Delay (minutes)')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The forecasted values after the anamoly detection and handling is very close to the actual values of the test_data and the model is able to predict very closely to the actual values.","metadata":{}},{"cell_type":"code","source":"# Ensuring both are numpy arrays to facilitate calculations\nactuals = np.array(test_data_new['DEP_DELAY'])\nforecasts = np.array(ets_result.forecast(steps=len(test_data_new)))\n\n# Mean Absolute Error\nmae = np.mean(np.abs(forecasts - actuals))\n\n# Mean Squared Error\nmse = np.mean((forecasts - actuals) ** 2)\n\n# Root Mean Squared Error\nrmse = np.sqrt(mse)\n\n# Symmetric Mean Absolute Percentage Error \nsmape = np.mean(2.0 * np.abs(forecasts - actuals) / (np.abs(actuals) + np.abs(forecasts))) * 100\n\nprint(f\"MAE: {mae}\")\nprint(f\"MSE: {mse}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"SMAPE: {smape}%\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above error metrics gives more room for imorovement as on average the model’s forecasts are about 15 minutes away from the actual departure delay times. The provided values indicate the model has some predictive capability but is certainly not perfect. The errors suggest that while the forecast can capture the general pattern of departure delays, there are specific instances where it fails to predict accurately and some robust models such as SARIMA can be used for better prediction. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport matplotlib.pyplot as plt\n\n\n# Plot Autocorrelation\nplot_acf(df_full['DEP_DELAY'], lags=30)  # You can adjust the number of lags as needed.\nplt.show()\n\n# Plot Partial Autocorrelation\nplot_pacf(df_full['DEP_DELAY'], lags=30)  # Adjust the number of lags as needed.\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:29:27.084403Z","iopub.execute_input":"2024-04-21T00:29:27.084882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Limitations","metadata":{}},{"cell_type":"markdown","source":"I tried to incorporate a couple of other models as well but they were computationally demanding and there was no way to incorporate those. Some of these models were SARIMA and LSTM. MY forst choice was LSTM but I did not get anywhere using it and hence decided on ARIMA. Whereas due to the computational challenges of SARIMA , I further dived into ETS model. ","metadata":{}}]}